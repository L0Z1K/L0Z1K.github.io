---
layout: post
title: 'DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation'
category: research
---

> ğŸ’¡ ë…¼ë¬¸ ë‚´ìš©ì´ ë„ˆë¬´ ì¬ë°Œê³  ì¸ìƒê¹Šì–´ì„œ ì´ì „ê³¼ëŠ” ë‹¤ë¥´ê²Œ ë‹¨ìˆœ ë…¼ë¬¸ ìš”ì•½ì´ ì•„ë‹Œ ì´í•´í•˜ê¸° ìœ„í•´ ë°œì•…í•˜ë©° ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤. 

NeurIPS 2020ì— Acceptedëœ ë…¼ë¬¸ì´ë‹¤. ë” ìì„¸í•œ ë‚´ìš©ì€ [ë§í¬](https://blog.alexandrecarlier.com/deepsvg/) ì°¸ì¡°í•˜ì.

<h3 align="center">Abstract</h3>

<p align="center"><img width="300" src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Bitmap_VS_SVG.svg/2560px-Bitmap_VS_SVG.svg.png"></p>

Scalable Vector Graphics(SVG)ëŠ” rasterizedí•œ imageì¸ `.png`, `.jpg`ì™€ ë‹¤ë¥´ê²Œ í•´ìƒë„ì˜ ë³€í™”ë¥¼ ì£¼ì–´ë„ ê·¸ì— ë§ì¶°ì„œ scaleë  ìˆ˜ ìˆë‹¤. ê·¸ë˜ì„œ SVGëŠ” ì´ë¯¸ì§€ ì‘ì—…ì— ìˆì–´ì„œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ëœë‹¤. ê·¸ëŸ¬ë‚˜ <mark>SVGëŠ” rasterized imageì™€ ë‹¬ë¦¬ deeplearning ë¶„ì•¼ì— ì•„ì§ê¹Œì§€ëŠ” ì˜ ì ìš©ë˜ê³  ìˆì§€ ëª»í•˜ë‹¤. ë‹¨ìˆœí•œ pixel í˜•ì‹ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ê¸°ì¡´ imageë“¤ ë³´ë‹¤ëŠ” ë‹¤ë£¨ê¸°ê°€ ê½¤ ê¹Œë‹¤ë¡­ê¸° ë•Œë¬¸ì´ë‹¤.</mark>

ì´ ë…¼ë¬¸ì—ì„œëŠ” SVG iconsì„ Deeplearning modelì— ì ìš©ì‹œì¼œ generationê³¼ interpolationì„ í•  ìˆ˜ ìˆëŠ” **DeepSVG**ë¥¼ ì†Œê°œí•œë‹¤. Interpolationì€ ë³´ê°„ë²•ì´ë¼ í•˜ë©°, ì—°ì†ì  ë³€ìˆ˜ ê°€ìš´ë° ê·¸ ì‚¬ì´ì˜ ë³€ìˆ˜ê°’ì— ëŒ€í•œ í•¨ìˆ˜ê°’ì„ êµ¬í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²ƒì´ë‹¤. ë§ì´ ê½¤ ì–´ë ¤ìš´ë° ê·¸ë¦¼ìœ¼ë¡œ ì„¤ëª…í•˜ìë©´,

<p align="center"><img width="600" alt="image" src="https://user-images.githubusercontent.com/64528476/134800456-08b19a7b-f5b8-4045-90da-c06a3d971ed0.png"></p>

ì™¼ìª½ê³¼ ì˜¤ë¥¸ìª½ì˜ svg iconì´ ê°ê° ìˆì„ ë•Œ, ê·¸ ë‘˜ì„ ì ë‹¹íˆ ì§¬ë½•ì‹œí‚¨ ì¤‘ê°„ ì‚°ë¬¼ë“¤ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. 

<h2>1. Introduction</h2>

Vector ImageëŠ” ë³´í†µ 2D shapeì˜ list í˜•íƒœë¡œ í‘œí˜„ëœë‹¤. ê° 2D shapeë“¤ì€ parametric curveë¡œ ì—°ê²°ëœ 2D pointë“¤ì˜ sequenceìœ¼ë¡œ encodingëœë‹¤. sequenceë¡œ encoding ë˜ê¸° ë•Œë¬¸ì— NLP Taskë‘ ë¹„ìŠ·í•˜ê²Œ ì ‘ê·¼í•˜ë©´ ë˜ì§€ ì•Šì„ê¹Œ? í•  ìˆ˜ë„ ìˆë‹¤. í•˜ì§€ë§Œ ë‘˜ ê°„ì˜ í° ì°¨ì´ì ì´ ìˆëŠ”ë° ë°”ë¡œ, <mark>SVG imageëŠ” <strong>permutation invariance</strong>í•˜ë‹¤ëŠ” ê²ƒì´ë‹¤.</mark>

**permutation invariance**ë€, sequence ë˜ëŠ” sequenceë¥¼ ì´ë£¨ëŠ” token ê°„ì˜ ìœ„ì¹˜ê°€ ë°”ë€Œì–´ë„ outputì€ ë™ì¼í•˜ë‹¤ëŠ” ê²ƒì´ë‹¤. NLPì—ì„œ ë‹¤ë£¨ëŠ” sequenceëŠ” ê·¸ë ‡ì§€ ì•Šë‹¤. I am 13, you are 14. ì´ë¼ëŠ” ë¬¸ì¥ê³¼ I am 14, you are 13. ì´ë¼ëŠ” ë¬¸ì¥ì˜ ì˜ë¯¸ëŠ” ë‹¤ë¥´ë‹¤.

SVG Imageì—ì„œ sequenceì˜ ìœ„ì¹˜ëŠ” ìƒê´€ì´ ì—†ë‹¤. ê²°êµ­ ê·¸ sequenceë“¤ì´ í•œë²ˆì— ëª¨ì—¬ 2D imageë¥¼ ì´ë£¨ê¸° ë•Œë¬¸ì´ë‹¤.

ë…¼ë¬¸ì—ì„œëŠ” Hierarchical Transformer-based architectureë¥¼ ì´ìš©í•´ vector graphicì„ ë‹¤ë£¬ë‹¤. EncoderëŠ” ê° shapeë“¤ì„ ê°œë³„ì ìœ¼ë¡œ encodingí•˜ê³  ì´ë¥¼ ì´ìš©í•´ latent vector $$z$$ë¥¼ ìƒì„±í•œë‹¤. DecoderëŠ” $$z$$ë¥¼ ê°€ì§€ê³  ê° shapeë“¤ì„ predictí•˜ê²Œ ëœë‹¤. ê° shapeë“¤ì€ í•©ì³ì§€ë©´ì„œ í•˜ë‚˜ì˜ SVG imageë¥¼ ìƒì„±í•œë‹¤.

<p align="center"><img width="600" alt="image" src="https://user-images.githubusercontent.com/64528476/134800951-9d644498-93bc-44b5-8af9-64590ad1bf6c.png"></p>

<mark>modelì˜ ì¤‘ìš”í•œ íŠ¹ì§•ì€ Decodingì„ non-autoregressivelyí•˜ê²Œ í•œë‹¤ëŠ” ì ì´ë‹¤.</mark>

ìœ„ ì‚¬ì§„ì˜ (a)ëŠ” Encoding ì‹œì— imageë¥¼ ë‹¤ ë•Œë ¤ë„£ê³  Decodingí•  ë•ŒëŠ” í•˜ë‚˜í•˜ë‚˜ ì”© autoregressiveí•˜ê²Œ í•œë‹¤. ì´ë“¤ì´ ì œì•ˆí•˜ëŠ” ëª¨ë¸(b)ì€ Encoding ì‹œì— 2D shapeë§ˆë‹¤ ê°ê° encoderì— ë„£ì–´ì£¼ê³  Decodingì‹œì—ëŠ” í•œë²ˆì— outputì´ ë‚˜ì˜¤ê²Œ ëœë‹¤.

<h2>2. DeepSVG</h2>

<h3>2.1. SVG Dataset and Representation</h3>

**SVG-Icons8 Dataset.** ì œëŒ€ë¡œ ëœ SVG Datasetì´ ì—†ì—ˆëŠ”ë° ìê¸°ë“¤ì´ 56ê°œ ì¹´í…Œê³ ë¦¬, ì´ 100,000ê°œ SVG ë°ì´í„° ë§Œë“¤ì—ˆë‹¤ê³  ì–˜ê¸°í•˜ëŠ” ê±°ë‹¤.

<mark><strong>SVG Representation.</strong></mark> SVG ImageëŠ” pathë“¤ì˜ setìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©°, ê° pathëŠ” íŠ¹ì • draw-commandì˜ seqeunceë¡œ ì´ë£¨ì–´ì§„ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìœ„ ì‚¬ì§„ì˜ ë‘ ê°œì˜ ë§í’ì„ ì´ ìˆëŠ”ë°, ê° ë§í’ì„ ì´ í•˜ë‚˜ì˜ pathì´ë©° ê° pathëŠ” ì ìœ¼ë¡œ splitë˜ì–´ ìˆë‹¤. ì´ë ‡ê²Œ splitëœ ê³¡ì„ ë“¤ì´ í•˜ë‚˜ì˜ draw-commandê°€ ëœë‹¤.

Draw-commandë¥¼ well-definedí•˜ì˜€ê³ , representationì€ ë°‘ì˜ í‘œë¥¼ ì°¸ê³ í•˜ì.

<p align="center"><img width="600" alt="image" src="https://user-images.githubusercontent.com/64528476/134801281-6cb55ca5-11f4-461f-bc4e-cec4639fdc5d.png"></p>

ìˆ˜ì‹ìœ¼ë¡œ Vector graphic image $$V$$ë¥¼ í‘œí˜„í•˜ìë©´, ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
V=\{P_{1},\dots,P_{N_{P}}\}
$$

$$P_{i}$$ëŠ” pathë¥¼ ì˜ë¯¸í•˜ë©°, ì´ëŠ” ë˜ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ëœë‹¤.

$$
P_{i} = (S_{i}, f_{i}, v_{i})
$$

$$v_{i} \in \{0,1\}$$ëŠ” ì´ pathê°€ visibleí•œ ê²ƒì¸ì§€ ë‚˜íƒ€ë‚¸ë‹¤. imageì—ì„œ visibleí•˜ì§€ ì•Šë‹¤ë©´ ì™œ ìˆëŠ”ê±°ì§€? ì‹¶ê² ì§€ë§Œ ì´ìœ ëŠ” ë’¤ì—ì„œ ë‚˜ì˜¨ë‹¤.

$$f_{i} \in \{0,1,2\}$$ëŠ” ì´ path ë‚´ë¶€ë¥¼ ìƒ‰ê¹”ë¡œ ì¹ í•˜ëŠ” ê±´ì§€ ë‚˜íƒ€ë‚¸ë‹¤. ê° valueëŠ” *outline*, *fill*, *erase*ì— mappingëœë‹¤. *erase*ëŠ” pathë“¤ì´ ê²¹ì³¤ì„ ë•Œ, ìš©ì´í•˜ê²Œ ì‚¬ìš©ë  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

$$S_{i}$$ëŠ” commandë“¤ì˜ sequenceë¡œ í‘œí˜„ëœë‹¤.

$$
S_{i}=(C_{i}^{1},\dots,C_{i}^{N_{c}})
$$

$$C_{i}^{j}$$ëŠ” commandë¡œ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ëœë‹¤.

$$
C_{i}^{j} = (c_{i}^{j},X_{i}^{j})
$$

$$c_{i}^{j} \in \{ \text{<SOS>},m,l,c,z,\text{<EOS>}\}$$ëŠ” command typeì„ ë‚˜íƒ€ë‚´ë©°, $$X_{i}^{j}=({q_{x_{1}}^{j}}_{,i},{q_{y_{1}}^{j}}_{,i},{q_{x_{2}}^{j}}_{,i},{q_{y_{2}}^{j}}_{,i},{x_{2}^{j}}_{,i},{y_{2}^{j}}_{,i}) \in \mathbb{R}^{6}$$ëŠ” argument listì´ë‹¤. ìœ„ì˜ í…Œì´ë¸”ì„ ë³´ë©´ ìµœëŒ€ argumentê°€ 6ê°œë¼ $$\mathbb{R}^{6}$$ spaceë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤. ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” argumentë¥¼ -1ë¡œ setí•œë‹¤.

ì´ì²˜ëŸ¼ <mark>íš¨ìœ¨ì ì¸ parallel processingì„ ìœ„í•´, </mark>$$N_{P}$$, $$N_{C}$$<mark>ë¥¼ fixed numberë¡œ ì‚¬ìš©í•˜ëŠ”ë° ì´ëŸ¬ê¸° ìœ„í•´ visibleì„ ì²´í¬í•´ì£¼ëŠ” varaibleì´ ìˆëŠ” ê²ƒì´ë‹¤!</mark> Imageì— pathê°€ 2ê°œë¿ì¸ë°, $$N_{P}$$ê°€ 10ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤ë©´, ë‚˜ë¨¸ì§€ 8ê°œì˜ pathëŠ” ì•„ë¬´ ê°’ì´ë‚˜ ì ì–´ë†“ê³  $$v_{i}$$ë¥¼ 0ìœ¼ë¡œ setí•´ì£¼ë©´ ëœë‹¤. NLPì—ì„œ padding í•´ì£¼ëŠ” ë©”ì»¤ë‹ˆì¦˜ê³¼ ë™ì¼í•˜ë‹¤ê³  ë³´ë©´ ëœë‹¤.

<h3>2.2. SVG Embedding</h3>

ê° $$C_{i}^{j}$$ëŠ” dimension $$d_{E}$$ spaceì— embedding ì‹œì¼œì¤€ë‹¤. Embedding vector $$e_{i}^{j} \in \mathbb{R}^{d_{E}}$$ëŠ” 3ê°œ embedding í•©ìœ¼ë¡œ ì´ë¤„ì§„ë‹¤.

$$
e_{i}^{j} = {e_{cmd}^{j}}_{,i} + {e_{coord}^{j}}_{,i} + {e_{ind}^{j}}_{,i}
$$

**Command embedding.** Command typeì´ 6ì°¨ì› one-hot vector $$\delta_{c_{i}^{j}}$$ë¡œ encodingë˜ì–´ $$W_{cmd} \in \mathbb{R}^{d_{E}\times 6}$$ì— projectëœë‹¤.

$$
{e_{cmd}^{j}}_{,i} = W_{cmd} \delta_{c_{i}^{j}}
$$

**Coordinate embedding.** Input ì¢Œí‘œë¥¼ 8bitë¡œ ì–‘ìí™”ì‹œí‚¨ë‹¤.(0~255) ë˜í•œ ì¢Œí‘œ argumentë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë„ ì¶”ê°€í•˜ì—¬ ì´ 257ì°¨ì› spaceë¡œ embeddingí•´ì¤€ë‹¤. ê° ì¢Œí‘œëŠ” weight matrix $$W_{X} \in \mathbb{R}^{d_{E} \times 257}$$ë¥¼ í†µí•´ embeddingë˜ë©°, ì¢Œí‘œê°€ ì´ 6ê°œì´ë¯€ë¡œ concatenateí•˜ë©´ $$6d_{E}$$ ì°¨ì› vectorê°€ ë˜ë©°, ì´ë¥¼ ë‹¤ì‹œ $$W_{coord} \in \mathbb{R}^{d_{E} \times 6d_{E}}$$ë¥¼ í†µí•´ embeddingì‹œí‚¨ë‹¤.

$$
{e_{coord}^{j}}_{,i}=W_{coord}\text{vec}(W_{X}X_{i}^{j})
$$

**Index embedding.** ì£¼ì–´ì§„ sequenceì—ì„œ commandì˜ ìœ„ì¹˜ë¥¼ í‘œì‹œí•˜ëŠ” vectorë¡œ one-hot vector $$\delta_{j} \in \mathbb{R}^{N_{S}}$$ë¥¼ $$W_{ind} \in \mathbb{R}^{d_{E} \times N_{S}}$$ë¥¼ í†µí•´ embeddingì‹œí‚¨ë‹¤.

$$
{e_{ind}^{j}}_{,i}=W_{ind} \delta_{j} \in \mathbb{R}^{d_{E}}
$$

<h3>2.3 Hierarchical Generative Network</h3>

ì œì•ˆí•˜ëŠ” NetworkëŠ” variational auto-encoder(VAE)ì´ë‹¤. VAEì™€ AEì˜ ì°¨ì´ì ì„ ì˜ ëª¨ë¥´ê³  ìˆì—ˆëŠ”ë°, [ì´ ë¸”ë¡œê·¸](https://velog.io/@ohado/ë”¥ëŸ¬ë‹-ê°œë…-1.-VAEVariational-Auto-Encoder) ë³´ê³  ì´í•´í–ˆìœ¼ë‹ˆ ì°¸ê³ í•˜ë©´ ì¢‹ë‹¤.

**Feed-forward prediction.** ëª¨ë“  pathì— ëŒ€í•´ ìš°ë¦¬ëŠ” $$C_{i}^{j}$$ë¥¼ predictí•˜ê²Œ ë˜ë©°, ì´ëŠ” non-autoregressivelyí•˜ê²Œ ì´ë¤„ì§„ë‹¤. ìš°ë¦¬ì˜ generative modelì€ ë‹¤ìŒê³¼ ê°™ì´ factorized ëœë‹¤.

$$
\begin{aligned}
p(\hat{V}|z, \theta)&=\prod_{i=1}^{N_{P}}p(\hat{v_{i}}|z,\theta)p(\hat{f_{i}}|z,\theta)p(\hat{S_{i}}|z,\theta)\\
                    &=\prod_{i=1}^{N_{P}}p(\hat{v_{i}}|z,\theta)p(\hat{f_{i}}|z,\theta)\prod_{j=1}^{N_{C}}p(\hat{c_{i}^{j}}|z,\theta)p(\hat{X_{i}^{j}}|z,\theta)
\end{aligned}
$$

ì‹ì„ ë³´ë©´, ìˆœì„œ ìƒê´€ì—†ì´ ë‹¤ ê³±í•´ì§€ë‹ˆ permutation invarianceë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. $$z$$ëŠ” latent vectorì´ë‹¤.

<p align="center"><img width="600" alt="image" src="https://user-images.githubusercontent.com/64528476/134805909-7d8807cf-4f5a-4d8c-afea-4e9515a9f499.png"></p>

**Encoder.** ê° path $$P_{i}$$ëŠ” path encoder $$E^{(1)}$$ì— ì˜í•´ encodingëœë‹¤. outputìœ¼ë¡œ $$({e^{\prime}}_{i}^{j})_{j=1}^{N_{C}}$$ì´ ë‚˜ì˜¤ê³  ì´ë¥¼ average-pool í•´ì£¼ì–´ $$u_{i}$$ë¥¼ ìƒì„±í•œë‹¤. ìƒì„±ëœ $$u_{i}$$ë“¤ì´ encoder $$E^{(2)}$$ì˜ inputìœ¼ë¡œ ë“¤ì–´ê°€ê³  outputìœ¼ë¡œ Gaussian distributionì¸ $$\hat{\mu}$$, $$\hat{\sigma}$$ê°€ ë‚˜ì˜¨ë‹¤. ì´ distributionìœ¼ë¡œ latent vector $$z$$ê°€ ë„ì¶œëœë‹¤.

**Decoder.** Decoder $$D^{(2)}$$ëŠ” $$z$$ë¥¼ ë°›ì•„ ê° path encoding $$\hat{u_{i}}$$, $$\hat{f_{i}}$$, $$\hat{v_{i}}$$ë¥¼ predictí•œë‹¤. Decoder $$D^{(1)}$$ëŠ” $$\hat{u_{i}}$$ë¥¼ $$(\hat{C_{i}^{1}},\dots,\hat{C_{i}^{N_{C}}})$$ë¡œ decodingí•œë‹¤.

ìœ„ì˜ ì‚¬ì§„ì˜ $$\pi$$ëŠ” Permutation Matrixë¡œ ground truthì™€ predictì˜ orderê°€ ë§ì§€ ì•Šì„ ë•Œ, Loss ê³„ì‚° ì‹œ pathë“¤ì„ ì˜ ì§ì§€ì–´ ì£¼ê¸° ìœ„í•¨ì´ë‹¤.

<h3>2.4. Training Objective</h3>

Training lossëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

<p align="center"><img width="600" alt="image" src="https://user-images.githubusercontent.com/64528476/134806376-662411fd-494d-49b9-a850-301e439c8a26.png"></p>

$$l$$ì€ Cross-Entropy lossì´ë©°, $$v_{i}$$, $$S_{i}$$, $$f_{i}$$ ê°ê° lossì—ì„œ ê°€ì¤‘ì¹˜ $$w$$ê°€ ë¶€ì—¬ëœë‹¤. ì˜¤ë¥¸ìª½ í•­ì— $$v_{i}$$ê°€ ë¶™ì–´ìˆëŠ” ì´ìœ ëŠ” visibleí•œ pathì— ëŒ€í•´ì„œë§Œ lossë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•¨ì´ë‹¤. ì‹ì´ êµ‰ì¥íˆ ì§ê´€ì ì´ë¼ ì¢‹ì•˜ë‹¤.

Lossë¥¼ ì œëŒ€ë¡œ ê³„ì‚°í•´ì£¼ê¸° ìœ„í•´ì„œëŠ” ì‹ì—ì„œ $$\hat{i}$$ì™€ $$i$$ê°€ ì˜ë¯¸í•˜ëŠ” pathê°€ ë™ì¼í•´ì•¼ í•œë‹¤. ì¦‰, $$i=\pi(\hat{i})$$ì„ ë§Œì¡±ì‹œì¼œì•¼ í•œë‹¤. ì œëŒ€ë¡œ permutationì„ ì•ˆí•´ì£¼ë©´ ì´ì „ ê·¸ë¦¼ì—ì„œ í° ë§í’ì„ í•˜ê³  ì‘ì€ ë§í’ì„ ì„ ë¹„êµí•´ë²„ë¦¬ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. $$\pi$$ë¥¼ ì–´ë–»ê²Œ ì •ì˜í•˜ëŠ” ì§€ ë…¼ë¬¸ì—ì„œ 2ê°€ì§€ ë°©ë²•ì„ ì œì‹œí•œë‹¤.

**Ordered assignment.** $$\pi$$ë¥¼ íŠ¹ì • ê¸°ì¤€ìœ¼ë¡œ ground-truth pathë¥¼ sortingí•˜ì—¬ ì •ì˜í•œë‹¤. ë…¼ë¬¸ì—ì„œëŠ” pathë“¤ì˜ ì‹œì‘ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ sortingí•˜ì—¬ ì¢‹ì€ ê²°ê³¼ë¥¼ ëƒˆë‹¤ê³  í•œë‹¤. Ordered assignment $$\pi_{ord}$$ë¥¼ ì‚¬ìš©í•˜ë©´ ìµœì¢… LossëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
L(\theta)=w_{KL}KL(p_{\theta}(z)||\mathcal{N}(0,I)) + \sum_{i=1}^{N_{P}}L_{\hat{i},\pi_{ord}(\hat{i})}(\theta)
$$

ì²«ë²ˆì§¸ í•­ì€ $$p_{\theta}$$ê°€ Gaussian distributionì„ ì¶”ì¢…í•˜ê¸° ìœ„í•´ KL divergenceë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒ ê°™ë‹¤.(ì¶”ì¸¡ì„..)

**Hungarian assignment.** $$\hat{i}$$ì™€ $$i$$ê°€ ì˜ë¯¸í•˜ëŠ” pathê°€ ë™ì¼í•  ë•Œ, lossê°€ ê°€ì¥ ì‘ì„ ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‹ˆ ëª¨ë“  $$\pi$$ì— ëŒ€í•´ lossë¥¼ ê³„ì‚°í•´ë³´ê³  loss ê°’ì´ minimumì¸ ê²ƒìœ¼ë¡œ ê³„ì‚°í•´ì£¼ë©´ ëœë‹¤.

(ì–¸ëœ»ë´ì„œëŠ” ìœ„ì˜ ë°©ë²•ë³´ë‹¤ ë§ì´ ë¹„íš¨ìœ¨ì ì¼ ê²ƒ ê°™ë‹¤. ê·¸ë˜ì„œ ê·¸ëŸ°ì§€ ê²°ê³¼ê°€ ìœ„ë³´ë‹¤ëŠ” ì¢‹ì§€ ì•Šë‹¤.)

$$
L(\theta)=w_{KL}KL(p_{\theta}(z)||\mathcal{N}(0,I)) + \min_{\pi \in S_{N_{P}}}\sum_{i=1}^{N_{P}}L_{\hat{i},\pi(\hat{i})}(\theta)
$$

**Training details.** AdamW optimizerë¥¼ ì‚¬ìš©í–ˆê³ , dropout, gradient clippingë„ ì ìš©í•˜ì˜€ë‹¤. 2ê°œ gpuë¡œ í•˜ë£¨ ì •ë„ ê±¸ë ¸ë‹¤ê³  í•œë‹¤.

<h2>3. Experiments</h2>

<p align="center"><img width="700" alt="image" src="https://user-images.githubusercontent.com/64528476/134812335-3eedc516-74d2-4dc5-bfe4-177b69b10523.png"></p>

ì‚¬ëŒí•œí…Œ ìœ„ì˜ ë„¤ê°œì˜ ëª¨ë¸ì„ ê°ê° ì‚¬ìš©í•´ ìƒì„±í•œ interpolationì„ ë³´ì—¬ì£¼ê³  rankë¥¼ ë§¤ê¸°ê²Œ í•˜ì˜€ë‹¤. í‘œë¥¼ ë³´ë‹¤ì‹œí”¼ Ordered assignmentë¥¼ ì“´ DeepSVGê°€ 1ë“±ì„ ê°€ì¥ ë§ì´ ì°¨ì§€í•˜ì˜€ë‹¤. ê°œì¸ì ìœ¼ë¡œ ì´ëŸ° ì‹ìœ¼ë¡œë„ evaluationí•œë‹¤ëŠ” ê²Œ ì‹ ë°•í–ˆë‹¤. í•­ìƒ public datasetì„ ê°€ì§€ê³  SOTAë‘ ë¹„êµí•´ì•¼ ë˜ëŠ” ì¤„ ì•Œì•˜ëŠ”ë°..

Quantitative measureë¥¼ í•˜ê¸° ìœ„í•´ 2ê°€ì§€ metricì„ ì œì•ˆí•œë‹¤.

**Reconstruction Error.** $$RE=d_{Chfr}(V,\hat{V})$$

$$
d_{Chfr}(V,\hat{V})=\cfrac{1}{N_{P}}\sum_{i=1}^{N_{P}}\min_{j}\int_{t}\min_{\tau}||P_{i}(t)-\hat{P_{j}}(\tau)||_{2}dt
$$

ì‚¬ì‹¤ ì´ ì‹ì€ ì œëŒ€ë¡œ ì´í•´ëª»í–ˆë‹¤.. ë°”ê¹¥ì˜ $$\min_{j}$$ë¶€ë¶„ì€ ì–´ë–¤ pathë¼ë¦¬ê°€ pairì¸ì§€ ëª¨ë¥´ë‹ˆ ê·¸ëƒ¥ ë‹¤ ë¹„êµí•˜ê³  minimumì„ ê³„ì‚°í•œë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.

**Interpolation Smoothless.** ISëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤.

$$
IS = \sum_{k=1}^{M}d_{Chfr}(V^{\alpha_{k-1}}, V^{\alpha_{k}}), \alpha_{k}=k/M
$$

ë§ê·¸ëŒ€ë¡œ ì´ì „ stateì—ì„œ ë‹¤ìŒ stateë¡œ ê°ˆë•Œ smoothí•˜ê²Œ ë„˜ì–´ê°€ëŠ” ì§€ë¥¼ $$d_{Chfr}$$ë¡œ ê³„ì‚°í•˜ëŠ” ê²ƒì´ë‹¤.

ë‘ Measureì—ì„œë„ ëª¨ë‘ Ordered assignmentë¥¼ ì“´ DeepSVGê°€ ìš°ì„¸í•¨ì„ ë³¼ ìˆ˜ ìˆì—ˆë‹¤.

<p align="center"><img width="700" alt="image" src="https://user-images.githubusercontent.com/64528476/134812699-17ace7b0-68a9-4f77-b8c1-153318d67b90.png"></p>

ë„¤ ê°œì˜ SVG Icon ì‚¬ì´ì—ì„œ interpolationëœ ê²°ê³¼ë¥¼ ë³´ë©´ ì°¸ ì‹ ê¸°í•˜ë‹¤.

<mark>Interpolationì´ smoothí•˜ê²Œ ì¼ì–´ë‚˜ë©´ ê·¸ë¦¼ì„ ê·¸ë ¤ë†“ê³  ë‘ ê·¸ë¦¼ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ì‹œì¼œì„œ ì•„ë˜ì™€ ê°™ì´ animationì„ ë§Œë“¤ìˆ˜ë„ ìˆë‹¤!</mark>

<p align="center"><img width="700" alt="image" src="https://user-images.githubusercontent.com/64528476/134812763-7fe60f21-9255-40b3-9b35-ce4dedd79f19.png"></p>

ë˜í•œ ì•„ë˜ì™€ ê°™ì´ latent vector ê°„ì˜ ì—°ì‚°ì„ í†µí•´ featureë¥¼ ë½‘ì•„ë‚´ì–´ manipulateí•  ìˆ˜ ìˆë‹¤.

<p align="center"><img width="400" alt="image" src="https://user-images.githubusercontent.com/64528476/134812850-982b0803-886b-4242-9cfd-f8de5b609dd5.png"></p>

<h2>4. Conclusion</h2>

Hierarchical Networkë¡œ SVG icon interpolationê³¼ manipulationì„ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ì˜€ë‹¤. ì´ê²ƒì€ image vectorisation, style transfer, classification, animation ë“± ì—¬ëŸ¬ ë§ì€ taskì— ì ìš©ë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤. SVG representationë„ ì˜ ë˜ì–´ì„œ ì´ ëª¨ë¸ì„ baseë¡œ ë” ë§ì€ ì—°êµ¬ê°€ ì´ë¤„ì§€ë©´ ì¢‹ê² ë‹¤.

<h3>References</h3>

[1] [DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation](https://arxiv.org/pdf/2007.11301.pdf)

- - -

<h3>Comments</h3>

ì¹œêµ¬ê°€ ë˜ ë˜ì ¸ì¤¬ë˜ ë…¼ë¬¸ì´ì—ˆê³  ë„ˆë¬´ ì–´ë ¤ì›Œ ë³´ì—¬ì„œ ì•ˆ ì½ì„ê¹Œ í–ˆëŠ”ë° ì‹œê°„ì´ ì¢€ ì—¬ìœ ë¡œì›Œì„œ ì½ì„ ìˆ˜ ìˆì—ˆë‹¤. ë…¼ë¬¸ í¬ìŠ¤íŒ…ì„ ì•ˆí•œì§€ 3ë‹¬ì´ ë˜ì—ˆê³  ë³„ë¡œ í•˜ê¸° ê·€ì°®ì•„ì„œ ì–˜ë„ ê·¸ëƒ¥ ì½ê³  ë„˜ì–´ê°€ë ¤ê³  í–ˆì—ˆëŠ”ë° ì£¼ì œê°€ ë„ˆë¬´ ì¬ë°Œê³  ê·¸ì— ë°˜í•´ í•œêµ­ì–´ë¡œ ì •ë¦¬ëœ í¬ìŠ¤íŒ…ì´ ì—†ì–´ì„œ ë‚´ê°€ ì‘ì„±í•´ì•¼ê² ë‹¤ê³  ë§˜ë¨¹ì—ˆë‹¤. Image ë¶„ì•¼ TaskëŠ” í•­ìƒ raster imageë¥¼ ë‹¤ë¤˜ì—ˆëŠ”ë° svg ë‹¤ë£¨ëŠ” ê²ƒì„ ì œì•ˆí•˜ëŠ” ê²Œ ë„ˆë¬´ ì‹ ë°•í–ˆë‹¤. ì •ë§ ì²˜ìŒë³´ëŠ” ë‚´ìš©ë“¤ íˆ¬ì„±ì´ë¼ ë‹¤ ì¬ë°Œì—ˆë‹¤. íŠ¹íˆ, Loss ê³„ì‚°ì‹ì´ ì§ê´€ì ìœ¼ë¡œ ì´í•´ë˜ì–´ì„œ ì¢‹ì•˜ê³  ì œì•ˆí•œ measureë„ ê·¸ëŸ´ë“¯ í–ˆë‹¤. ë‹¨ìˆœí•œ ë…¼ë¬¸ ìš”ì•½ì´ ì•„ë‹Œ ì •ë¦¬ë¼ì„œ ê±°ì˜ 3-4ì‹œê°„ ê±¸ë¦° ê²ƒ ê°™ë‹¤. ê·¸ë˜ë„ ë‚´ìš©ì´ ì¬ë°Œì–´ì„œ ì¦ê²ê²Œ í•  ìˆ˜ ìˆì—ˆë‹¤. ì •ë§ ì €ìê°€ ë§í•œëŒ€ë¡œ ì•„ì§ explorableí•œ ë¶€ë¶„ì´ ë§ë‹¤ê³  ëŠê»´ì ¸ì„œ ì•„ì´ë””ì–´ê°€ ìƒ˜ì†Ÿê¸°ë¥¼ ë°”ë¼ê³  ìˆë‹¤. 

- - -